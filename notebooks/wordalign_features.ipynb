{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a0453510-71c2-4a70-960a-970940bfc5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstring = \"\"\"\n",
    "Helper script that takes a folder of speech reps (wav2vec2, mel-spec, etc.)\n",
    "and aligns them at word-level using MFA alignments.\n",
    "\n",
    "Speech reps corresponding to word tokens in the corpus are then saved individually to an output folder\n",
    "with the following structure:\n",
    "- data_path\n",
    "    - word1\n",
    "        - word1_LJ010-0292_001.pt\n",
    "        - word1_LJ010-0292_002.pt\n",
    "        - ...\n",
    "    - word2\n",
    "        - word2_LJ001-0012_001.pt\n",
    "        - word2_LJ002-0024_001.pt\n",
    "        - ...\n",
    "    - ...\n",
    "\n",
    "- word1, word2, ... subfolders refer to a particular wordtype in the corpus.\n",
    "- .pt files contain speech representations that map to a particular example of a wordtype.\n",
    "  It is named as:\n",
    "    <wordtype>_<utt id>_<numbered occurrence in the utterance>.pt\n",
    "\n",
    "Example usage:\n",
    "    #hubert w/ padding offset\n",
    "    cd ~/fairseq\n",
    "    python examples/lexicon_learner/wordalign_speechreps.py \\\n",
    "        -t hubert \\\n",
    "        --padding_idx_offset 1 \\\n",
    "        -s /home/s1785140/fairseq/examples/lexicon_learner/lj_speech_quantized.txt \\\n",
    "        -a /home/s1785140/data/ljspeech_MFA_alignments \\\n",
    "        -o /home/s1785140/data/ljspeech_hubert_reps/hubert-base/layer-6/word_level_with_padding_idx_offset\n",
    "\n",
    "    #hubert w/o padding offset\n",
    "    cd ~/fairseq\n",
    "    python examples/lexicon_learner/wordalign_speechreps.py \\\n",
    "        -t hubert \\\n",
    "        --padding_idx_offset 0 \\\n",
    "        -s /home/s1785140/fairseq/examples/lexicon_learner/lj_speech_quantized.txt \\\n",
    "        -a /home/s1785140/data/ljspeech_MFA_alignments \\\n",
    "        -o /home/s1785140/data/ljspeech_hubert_reps/hubert-base/layer-6/word_level_without_padding_idx_offset\n",
    "\n",
    "    #wav2vec2\n",
    "    cd ~/fairseq\n",
    "    python examples/lexicon_learner/wordalign_speechreps.py \\\n",
    "        -t wav2vec2 \\\n",
    "        -s /home/s1785140/data/ljspeech_wav2vec2_reps/wav2vec2-large-960h/layer-15/utt_level \\\n",
    "        -a /home/s1785140/data/ljspeech_MFA_alignments \\\n",
    "        -o /home/s1785140/data/ljspeech_wav2vec2_reps/wav2vec2-large-960h/layer-15/word_level\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ed31824-8d7f-4e8c-a96b-937915cfc08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imitate CLAs\n",
    "import sys\n",
    "sys.argv = [\n",
    "    'train.py',\n",
    "    '--type', 'mel',\n",
    "    '--padding_idx_offset', '0',\n",
    "    '--input_directory', '/home/s1785140/data/ljspeech_fastpitch/mels',\n",
    "    '--alignments', '/home/s1785140/data/ljspeech_fastpitch/aligns', \n",
    "    '--output_directory', '/home/s1785140/data/ljspeech_fastpitch/wordaligned_mels',\n",
    "    \n",
    "    # FOR TESTING\n",
    "    # '--input_directory', '/home/s1785140/data/ljspeech_fastpitch/mels_test',\n",
    "    # '--alignments', '/home/s1785140/data/ljspeech_fastpitch/aligns_test', \n",
    "    # '--output_directory', '/home/s1785140/data/ljspeech_fastpitch/wordaligned_mels_test',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d3f0393f-64f2-4056-b219-a3e4f557516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import tgt\n",
    "import string\n",
    "\n",
    "SAMPLING_RATE = 22050\n",
    "HOP_LENGTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "050c2ce5-b47b-4bf5-96a1-fd8bedc6330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_textgrid(tier, sampling_rate, hop_length, ignore_all_pauses=True):\n",
    "    # latest MFA replaces silence phones with \"\" in output TextGrids\n",
    "    sil_phones = [\"sil\", \"sp\", \"spn\", \"\"]\n",
    "    utt_start_time = tier[0].start_time\n",
    "    utt_end_time = tier[-1].end_time\n",
    "    phones = []\n",
    "    durations = [] # NOTE includes durations of silences\n",
    "    start_frames = []\n",
    "    end_frames = []\n",
    "    for i, t in enumerate(tier._objects):\n",
    "        s, e, p = t.start_time, t.end_time, t.text\n",
    "        if p not in sil_phones:\n",
    "            phones.append(p)\n",
    "            start_frames.append(int(np.ceil(s * sampling_rate / hop_length)))\n",
    "            end_frames.append(int(np.ceil(e * sampling_rate / hop_length)))\n",
    "            durations.append(int(np.ceil(e * sampling_rate / hop_length)\n",
    "                                 - np.ceil(s * sampling_rate / hop_length)))\n",
    "        else:\n",
    "            if not ignore_all_pauses:\n",
    "                if (i == 0) or (i == len(tier) - 1):\n",
    "                    # leading or trailing silence\n",
    "                    phones.append(\"sil\")\n",
    "                else:\n",
    "                    # short pause between words\n",
    "                    phones.append(\"sp\")\n",
    "\n",
    "    n_samples = utt_end_time * sampling_rate\n",
    "    n_frames = n_samples / hop_length\n",
    "    # fix occasional length mismatches at the end of utterances when\n",
    "    # duration in samples is an integer multiple of hop_length\n",
    "    if n_frames.is_integer():\n",
    "        durations[-1] += 1\n",
    "    return phones, durations, start_frames, end_frames, utt_start_time, utt_end_time\n",
    "\n",
    "def save_to_disk(tensor, word, utt_id, count, output_directory):\n",
    "    output_directory = os.path.join(output_directory, word)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    save_path = os.path.join(output_directory, f'{word}__{utt_id}__occ{count}__seqlen{tensor.size(0)}.pt')\n",
    "    torch.save(tensor, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fee0cc05-4710-415d-a14a-368b60ca150e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mels from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 186/186 [00:00<00:00, 1714.08it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "186, 125",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [97], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# sanity check\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m num_of_utts \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(args\u001b[38;5;241m.\u001b[39malignments)), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_of_utts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(args\u001b[38;5;241m.\u001b[39malignments))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m longest_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     43\u001b[0m longest_word_utt_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 186, 125"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-t', '--type', type=str, default='hubert',\n",
    "                    help='type of input speech reps that we are using, i.e. hubert wav2vec2 etc.')\n",
    "parser.add_argument('--padding_idx_offset', type=int, default=0,\n",
    "                    help='add 1 to token id of discrete reps in order to allow for padding_idx==0')\n",
    "parser.add_argument('-s', '--input_directory', type=str, required=True,\n",
    "                    help='path to single non-nested folder containing speech representations (.pt files) or txt file (hubert)')\n",
    "parser.add_argument('-a', '--alignments', type=str, required=True,\n",
    "                    help='path to single non-nested folder containing MFA alignments (.TextGrid files)')\n",
    "parser.add_argument('-o', '--output_directory', type=str, required=True,\n",
    "                    help='where to write word-level data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.type == \"hubert\":\n",
    "    with open(args.input_directory, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    num_of_utts = len(lines)\n",
    "    utt_id2speechreps = {l.split('|')[0]:l.split('|')[1] for l in lines}\n",
    "    utt_ids = sorted(utt_id2speechreps.keys()) # ensure we always process utts in same alphabetical order\n",
    "elif args.type == \"wav2vec2\":\n",
    "    num_of_utts = len(os.listdir(args.input_directory))\n",
    "    utt_ids = sorted(file.split('.')[0] for file in os.listdir(args.input_directory))\n",
    "elif args.type == \"mel\":\n",
    "    utt_ids = list(sorted(file.split('.')[0] for file in os.listdir(args.input_directory)))\n",
    "    utt_ids = utt_ids\n",
    "    num_of_utts = len(utt_ids)\n",
    "    utt_id2speechreps = {}\n",
    "    print(\"loading mels from disk\")\n",
    "    for utt_id in tqdm(utt_ids):\n",
    "        # load mel data\n",
    "        p = os.path.join(args.input_directory, f'{utt_id}.pt')\n",
    "        mel = torch.load(p).transpose(0,1) #[seqlen, feats]\n",
    "        utt_id2speechreps[utt_id] = mel\n",
    "else:\n",
    "    raise ValueError(f\"invalid input type {args.type}\")\n",
    "\n",
    "# sanity check\n",
    "assert num_of_utts == len(os.listdir(args.alignments)), f\"{num_of_utts}, {len(os.listdir(args.alignments))}\"\n",
    "\n",
    "longest_word = ''\n",
    "longest_word_utt_id = ''\n",
    "longest_word_num_frames = 0\n",
    "\n",
    "# split each speech reps file using the word-level alignments\n",
    "print(\"split speech reps using word alignments\")\n",
    "for utt_id in tqdm(utt_ids):\n",
    "    # load speech reps\n",
    "    if args.type == \"hubert\":\n",
    "        reps = utt_id2speechreps[utt_id]\n",
    "        reps = [int(s)+args.padding_idx_offset for s in reps.split(' ')] # NOTE add 1 to each index so that 0 is available as a padding_idx\n",
    "        reps = torch.tensor(reps)\n",
    "        reps.requires_grad = False\n",
    "\n",
    "        # check dimensions\n",
    "        if reps.dim() == 1:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"speech representations have an incorrect number of dimensions\")\n",
    "    elif args.type == \"mel\":\n",
    "        reps = utt_id2speechreps[utt_id]\n",
    "        reps.requires_grad = False\n",
    "\n",
    "        # check dimensions\n",
    "        if reps.dim() == 2 and reps.size(1) == 80:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"speech representations have an incorrect number of dimensions\")\n",
    "    else:\n",
    "        raise ValueError(f\"invalid input type {args.type}\")\n",
    "\n",
    "    tg_path = f\"{args.alignments}/{utt_id}.TextGrid\"\n",
    "    tg = tgt.io.read_textgrid(tg_path, include_empty_intervals=True)\n",
    "    words, all_durs, start_frames, end_frames, utt_start, utt_end = parse_textgrid(tg.get_tier_by_name('words'), SAMPLING_RATE, HOP_LENGTH)\n",
    "    \n",
    "    word_occ_in_utt_counter = Counter()\n",
    "    mel = utt_id2speechreps[utt_id]\n",
    "    assert mel.size(0) == sum(all_durs) # verify that MFA frame durations match up with the extracted mels\n",
    "    for word, dur, start_frame, end_frame in zip(words, all_durs, start_frames, end_frames):\n",
    "        for c in word:\n",
    "            if c not in string.ascii_lowercase:\n",
    "                print(f'WARNING: char {c} in word {word}')\n",
    "        \n",
    "        word_dur = end_frame - start_frame \n",
    "        if word_dur > longest_word_num_frames:\n",
    "            longest_word_num_frames = word_dur\n",
    "            longest_word = word\n",
    "            longest_word_utt_id = utt_id\n",
    "            \n",
    "        word_occ_in_utt_counter[word] += 1\n",
    "        wordaligned_mel = mel[start_frame:end_frame]\n",
    "        extracted_timesteps = wordaligned_mel.size(0)\n",
    "        assert dur == extracted_timesteps == word_dur, f\"{dur=}, {extracted_timesteps=}, {word_dur=}\"\n",
    "        save_to_disk(wordaligned_mel, word, utt_id, word_occ_in_utt_counter[word], args.output_directory)\n",
    "\n",
    "print(\"wordtype with longest num of timesteps is\", longest_word, \"from\", longest_word_utt_id, \"with len\", longest_word_num_frames)\n",
    "print(\"you can set transformer max_source_positions to this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aafd1ec-b5dc-4a8e-917d-a0625849034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_path = os.path.join(args.alignments, 'LJ001-0007.TextGrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050cc165-44f1-42a8-b170-a981414c8a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = tgt.io.read_textgrid(tg_path, include_empty_intervals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221e92f-eb50-4d8f-9d21-740b6e07f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg.get_tier_by_name('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286396f-375c-4694-b023-16e94c4838f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, durs, start_frames, end_frames, utt_start, utt_end = parse_textgrid(tg.get_tier_by_name('words'), SAMPLING_RATE, HOP_LENGTH)\n",
    "print(words, durs, start_frames, end_frames, utt_start, utt_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e21c3-6e19-4d7a-bb58-4dcfca2487e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
