{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a57c43-701b-498f-b397-1f8a3ab96bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea9ef19-7aa8-4e6c-9658-fb75b87072c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsz = 3\n",
    "max_len = 9\n",
    "lens = torch.tensor([1,4,9]).unsqueeze(1) \n",
    "\n",
    "m = torch.arange(max_len)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b2ab97-18e2-491c-b6dd-d55b2c3e2b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1260589-bef2-4a75-af06-74ba01270a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.repeat(bsz, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44730fee-4eec-42b5-87a8-f65ff32a85a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = m.expand(bsz, max_len)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e435fd3-79b7-44f1-806b-5cd2c725c558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~(m < lens) # tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edca457-b6bf-4fb5-a57a-28e1c31a7ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db45cdd4-f518-469c-800e-8be66e343dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src_key_padding_mask(bsz, max_len, lens):\n",
    "    \"\"\"return a Boolean mask for a list or tensor of sequence lengths\n",
    "    True for values in tensor greater than sequence length\n",
    "\n",
    "    bsz (int)\n",
    "    max_len (int): max seq len of item in batch\n",
    "    lens [bsz]: list or tensor of lengths\n",
    "    \"\"\"\n",
    "    if type(lens) == list:\n",
    "        lens = torch.tensor(lens)\n",
    "    assert lens.dim() == 1\n",
    "    \n",
    "    lens = lens.unsqueeze(1) # [bsz] -> [bsz, seq_len]\n",
    "    m = torch.arange(max_len)\n",
    "    m = m.expand(bsz, max_len) # repeat along batch dimension\n",
    "    m = (m < lens)\n",
    "    return ~m # tilde inverts a bool tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bed1131-e163-41c0-8b7a-dcd1492e4721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_src_key_padding_mask(3, 9, torch.tensor([1,4,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b0b5f1-bf03-468b-9e47-9aa9343b623d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_src_key_padding_mask(3, 9, [1,4,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f5d280-905f-4c83-a067-57cdb6dd24ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
