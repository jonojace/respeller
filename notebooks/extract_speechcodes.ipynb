{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256b7c1-3788-471f-9989-cd5415cddfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from textless.data.speech_encoder import SpeechEncoder\n",
    "\n",
    "dense_model_name = \"hubert-base-ls960\"\n",
    "quantizer_name, vocab_size = \"kmeans\", 100\n",
    "\n",
    "input_file = \"/home/s1785140/data/ljspeech_fastpitch/wavs/input.wav\"\n",
    "\n",
    "# now let's load an audio example\n",
    "waveform, sample_rate = torchaudio.load(input_file)\n",
    "\n",
    "# We can build a speech encoder module using names of pre-trained\n",
    "# dense and quantizer models.  The call below will download\n",
    "# appropriate checkpoints as needed behind the scenes. We can\n",
    "# also construct an encoder by directly passing model instances\n",
    "encoder = SpeechEncoder.by_name(\n",
    "    dense_model_name=dense_model_name,\n",
    "    quantizer_model_name=quantizer_name,\n",
    "    vocab_size=vocab_size,\n",
    "    deduplicate=True,\n",
    ").cuda()\n",
    "\n",
    "\n",
    "# now convert it in a stream of deduplicated units (as in GSLM)\n",
    "encoded = encoder(waveform.cuda())\n",
    "# encoded is a dict with keys ('dense', 'units', 'durations').\n",
    "# It can also contain 'f0' if SpeechEncoder was initialized\n",
    "# with need_f0=True flag.\n",
    "units = encoded[\"units\"]  # tensor([71, 12, 57, ...], ...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
