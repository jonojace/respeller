{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f5a3c3-31af-4835-88ee-4410bc5af326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de0d84a-9335-48be-8bfb-ba9cbbf0dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53034b89-b847-4927-a604-cc6cb78516c2",
   "metadata": {},
   "source": [
    "# dev train loop + model for respeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc78f43f-f8f6-4ffc-94b2-5aa10bdb06d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imitate CLAs\n",
    "import sys\n",
    "sys.argv = [\n",
    "    'train.py',\n",
    "    '--fastpitch-chkpt', 'fastpitch/exps/test_addspaces_1_eos_dollar/FastPitch_checkpoint_50.pt',\n",
    "    '--input-type', 'char',\n",
    "    '--symbol-set', 'english_basic_lowercase',\n",
    "    # '--use-mas',\n",
    "    '--cuda',\n",
    "    '--n-speakers', '1',\n",
    "    '--use-sepconv',\n",
    "    '--add-spaces',\n",
    "    '--eos-symbol', '$',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfb56b-58ed-447f-9308-a25d1e92cbc0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f776e058-d463-414a-b612-c6540f40a650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s1785140/miniconda3/envs/fastpitch/lib/python3.8/site-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 6103. The TBB threading layer is disabled.\n",
      "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train respeller model\n",
    "\n",
    "We backpropagate loss from pretrained TTS model to a Grapheme-to-Grapheme (G2G) respeller model to help it respell words\n",
    "into a simpler form\n",
    "\n",
    "Intermediated respellings are discrete character sequences\n",
    "We can backpropagate through these using gumbel softmax and the straight through estimator\n",
    "'''\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "from fastpitch import models as fastpitch_model\n",
    "from fastpitch.common.text.text_processing import TextProcessor\n",
    "\n",
    "from modules.model import EncoderRespeller\n",
    "from modules.gumbel_vector_quantizer import GumbelVectorQuantizer\n",
    "from modules.sdtw_cuda_loss import SoftDTW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4752f248-d859-4a78-8c79-4c65080948b6",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95a42be-2ea3-4b7e-a5e3-f506fdf2aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(parser):\n",
    "    \"\"\"Parse commandline arguments\"\"\"\n",
    "    # parser.add_argument('-o', '--output', type=str, required=True,\n",
    "    #                     help='Directory to save checkpoints')\n",
    "    parser.add_argument('-d', '--dataset-path', type=str, default='./',\n",
    "                        help='Path to dataset')\n",
    "\n",
    "    train_args = parser.add_argument_group('training setup')\n",
    "    train_args.add_argument('--cuda', action='store_true',\n",
    "                      help='Enable GPU training')\n",
    "    train_args.add_argument('--batch-size', type=int, default=16,\n",
    "                      help='Batchsize (this is divided by number of GPUs if running Data Distributed Parallel Training)')\n",
    "    train_args.add_argument('--seed', type=int, default=1337,\n",
    "                       help='Seed for PyTorch random number generators')\n",
    "    train_args.add_argument('--grad-accumulation', type=int, default=1,\n",
    "                       help='Training steps to accumulate gradients for')\n",
    "    train_args.add_argument('--epochs', type=int, default=100, #required=True,\n",
    "                       help='Number of total epochs to run')\n",
    "    train_args.add_argument('--epochs-per-checkpoint', type=int, default=10,\n",
    "                       help='Number of epochs per checkpoint')\n",
    "\n",
    "    data_args = parser.add_argument_group('dataset parameters')\n",
    "    cond_args = parser.add_argument_group('conditioning on additional attributes')\n",
    "    audio_args = parser.add_argument_group('log generated audio')\n",
    "    dist_args = parser.add_argument_group('distributed training setup')\n",
    "\n",
    "    arch_args = parser.add_argument_group('architecture')\n",
    "    arch_args.add_argument('--d-model', type=int, default=512,\n",
    "                       help='Hidden dimension of tranformer')\n",
    "    arch_args.add_argument('--latent-temp', type=tuple, default=(2, 0.5, 0.999995),\n",
    "                       help='Temperature annealling parameters for Gumbel-Softmax (start, end, decay)')\n",
    "\n",
    "    pretrained_tts_args = parser.add_argument_group('pretrained tts model')\n",
    "    # pretrained_tts_args.add_argument('--fastpitch-with-mas', type=bool, default=True,\n",
    "    #                   help='Whether or not fastpitch was trained with Monotonic Alignment Search (MAS)')\n",
    "    pretrained_tts_args.add_argument('--fastpitch-chkpt', type=str, required=True,\n",
    "                      help='Path to pretrained fastpitch checkpoint')\n",
    "    pretrained_tts_args.add_argument('--input-type', type=str, default='char',\n",
    "                      choices=['char', 'phone', 'pf', 'unit'],\n",
    "                      help='Input symbols used, either char (text), phone, pf '\n",
    "                      '(phonological feature vectors) or unit (quantized acoustic '\n",
    "                      'representation IDs)')\n",
    "    pretrained_tts_args.add_argument('--symbol-set', type=str, default='english_basic_lowercase',\n",
    "                      help='Define symbol set for input sequences. For quantized '\n",
    "                      'unit inputs, pass the size of the vocabulary.')\n",
    "    pretrained_tts_args.add_argument('--n-speakers', type=int, default=1,\n",
    "                      help='Condition on speaker, value > 1 enables trainable '\n",
    "                      'speaker embeddings.')\n",
    "    # pretrained_tts_args.add_argument('--use-sepconv', type=bool, default=True,\n",
    "    #                   help='Use depthwise separable convolutions')\n",
    "\n",
    "    return parser\n",
    "\n",
    "def load_checkpoint(args, model, filepath):\n",
    "    if args.local_rank == 0:\n",
    "        print(f'Loading model and optimizer state from {filepath}')\n",
    "    checkpoint = torch.load(filepath, map_location='cpu')\n",
    "    sd = {k.replace('module.', ''): v\n",
    "          for k, v in checkpoint['state_dict'].items()}\n",
    "    getattr(model, 'module', model).load_state_dict(sd)\n",
    "    return model\n",
    "\n",
    "def freeze_weights(model):\n",
    "    # NB wait... won't this stop backprop of gradients?\n",
    "    # We just don't want to add the fastpitch/quantiser model weights to the optimiser...\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def init_embedding_weights(source_tensor, target_tensor):\n",
    "    \"\"\"copy weights inplace from source tensor to target tensor\"\"\"\n",
    "    target_tensor.requires_grad = False\n",
    "    target_tensor.copy_(source_tensor.clone().detach())\n",
    "    target_tensor.requires_grad = True\n",
    "\n",
    "def load_pretrained_fastpitch(args):\n",
    "    # load chkpt\n",
    "    device = torch.device('cuda' if args.cuda else 'cpu')\n",
    "    model_config = fastpitch_model.get_model_config('FastPitch', args)\n",
    "    fastpitch = fastpitch_model.get_model('FastPitch', model_config, device, forward_is_infer=True)\n",
    "    load_checkpoint(args, fastpitch, args.fastpitch_chkpt)\n",
    "    # get information about grapheme embedding table\n",
    "    n_symbols = fastpitch.encoder.word_emb.weight.size(0)\n",
    "    grapheme_embedding_dim = fastpitch.encoder.word_emb.weight.size(1)\n",
    "    return fastpitch, n_symbols, grapheme_embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b41f829-86ec-4d6f-a829-cd5fa032c819",
   "metadata": {},
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff82f08-8500-40f7-ab53-0d2d76b3c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Respeller Training', allow_abbrev=False)\n",
    "parser = parse_args(parser)\n",
    "args, _unk_args = parser.parse_known_args()\n",
    "\n",
    "parser = fastpitch_model.parse_model_args('FastPitch', parser)\n",
    "args, unk_args = parser.parse_known_args()\n",
    "if len(unk_args) > 0:\n",
    "    raise ValueError(f'Invalid options {unk_args}')\n",
    "\n",
    "if args.cuda:\n",
    "    args.num_gpus = torch.cuda.device_count()\n",
    "    args.distributed_run = args.num_gpus > 1\n",
    "    args.batch_size = int(args.batch_size / args.num_gpus)\n",
    "else:\n",
    "    args.distributed_run = False\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "if args.distributed_run:\n",
    "    mp.spawn(train, nprocs=args.num_gpus, args=(args,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924bddc-abcd-42d1-b3db-30797ab59b1e",
   "metadata": {},
   "source": [
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8187a843-19ec-4aaf-842d-0e442a93fdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and optimizer state from fastpitch/exps/test_addspaces_1_eos_dollar/FastPitch_checkpoint_50.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FastPitch:\n\tUnexpected key(s) in state_dict: \"attention.query_proj.0.conv.weight\", \"attention.query_proj.0.conv.bias\", \"attention.query_proj.2.conv.weight\", \"attention.query_proj.2.conv.bias\", \"attention.query_proj.4.conv.weight\", \"attention.query_proj.4.conv.bias\", \"attention.key_proj.0.conv.weight\", \"attention.key_proj.0.conv.bias\", \"attention.key_proj.2.conv.weight\", \"attention.key_proj.2.conv.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m args\u001b[38;5;241m.\u001b[39mlocal_rank \u001b[38;5;241m=\u001b[39m rank\n\u001b[0;32m----> 4\u001b[0m tts, n_symbols, grapheme_embedding_dim \u001b[38;5;241m=\u001b[39m \u001b[43mload_pretrained_fastpitch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m respeller \u001b[38;5;241m=\u001b[39m EncoderRespeller(n_symbols\u001b[38;5;241m=\u001b[39mn_symbols, d_model\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39md_model)\n\u001b[1;32m      8\u001b[0m quantiser \u001b[38;5;241m=\u001b[39m GumbelVectorQuantizer(\n\u001b[1;32m      9\u001b[0m     in_dim\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39md_model,\n\u001b[1;32m     10\u001b[0m     codebook_size\u001b[38;5;241m=\u001b[39mn_symbols,  \u001b[38;5;66;03m# number of codebook entries\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     embedding_dim\u001b[38;5;241m=\u001b[39mgrapheme_embedding_dim,\n\u001b[1;32m     12\u001b[0m     temp\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlatent_temp,\n\u001b[1;32m     13\u001b[0m )\n",
      "Cell \u001b[0;32mIn [5], line 80\u001b[0m, in \u001b[0;36mload_pretrained_fastpitch\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     78\u001b[0m model_config \u001b[38;5;241m=\u001b[39m fastpitch_model\u001b[38;5;241m.\u001b[39mget_model_config(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFastPitch\u001b[39m\u001b[38;5;124m'\u001b[39m, args)\n\u001b[1;32m     79\u001b[0m fastpitch \u001b[38;5;241m=\u001b[39m fastpitch_model\u001b[38;5;241m.\u001b[39mget_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFastPitch\u001b[39m\u001b[38;5;124m'\u001b[39m, model_config, device, forward_is_infer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 80\u001b[0m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfastpitch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfastpitch_chkpt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# get information about grapheme embedding table\u001b[39;00m\n\u001b[1;32m     82\u001b[0m n_symbols \u001b[38;5;241m=\u001b[39m fastpitch\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mword_emb\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn [5], line 60\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[0;34m(args, model, filepath)\u001b[0m\n\u001b[1;32m     57\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(filepath, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m sd \u001b[38;5;241m=\u001b[39m {k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m): v\n\u001b[1;32m     59\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodule\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/fastpitch/lib/python3.8/site-packages/torch/nn/modules/module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1600\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1601\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1605\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FastPitch:\n\tUnexpected key(s) in state_dict: \"attention.query_proj.0.conv.weight\", \"attention.query_proj.0.conv.bias\", \"attention.query_proj.2.conv.weight\", \"attention.query_proj.2.conv.bias\", \"attention.query_proj.4.conv.weight\", \"attention.query_proj.4.conv.bias\", \"attention.key_proj.0.conv.weight\", \"attention.key_proj.0.conv.bias\", \"attention.key_proj.2.conv.weight\", \"attention.key_proj.2.conv.bias\". "
     ]
    }
   ],
   "source": [
    "rank = 0\n",
    "\n",
    "args.local_rank = rank\n",
    "tts, n_symbols, grapheme_embedding_dim = load_pretrained_fastpitch(args)\n",
    "\n",
    "respeller = EncoderRespeller(n_symbols=n_symbols, d_model=args.d_model)\n",
    "\n",
    "quantiser = GumbelVectorQuantizer(\n",
    "    in_dim=args.d_model,\n",
    "    codebook_size=n_symbols,  # number of codebook entries\n",
    "    embedding_dim=grapheme_embedding_dim,\n",
    "    temp=args.latent_temp,\n",
    ")\n",
    "\n",
    "init_embedding_weights(tts.encoder.word_emb.weight.unsqueeze(0), quantiser.vars)\n",
    "\n",
    "# batch_size, len_x, len_y, dims = 8, 15, 12, 5\n",
    "# x = torch.rand((batch_size, len_x, dims), requires_grad=True)\n",
    "# y = torch.rand((batch_size, len_y, dims))\n",
    "acoustic_loss_fn = SoftDTW(use_cuda=True, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e400b94a-4aa6-4a3b-8947-27b715933861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip_emb(fastpitch)\n",
    "\n",
    "# if args.respeller_loss:\n",
    "#     respelling_loss_fn = CrossEntropy()\n",
    "# else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc96877-6d23-4adb-a2db-3fbad4c5f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "symbol_set = 'english_basic_lowercase'\n",
    "text_cleaners = []\n",
    "gt_log_mel = torch.load('/home/s1785140/data/ljspeech_fastpitch/mels/LJ001-0001.pt')\n",
    "raw_text = 'printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition'\n",
    "\n",
    "# process text using same processor as fastpitch\n",
    "tp = TextProcessor(symbol_set, text_cleaners)\n",
    "text = torch.LongTensor(tp.encode_text(raw_text)).unsqueeze(0)\n",
    "\n",
    "batches.append((text, gt_log_mel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f510ca-97f6-4c1f-929a-a665fdf4394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d085d1-7da7-4063-aef5-69b79a40c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in batches:\n",
    "batch = batches[0]\n",
    "    \n",
    "###############################################################################################################\n",
    "# text, ssl_reps, e2e_asr_predictions, gt_log_mel = batch\n",
    "text, gt_log_mel = batch\n",
    "\n",
    "###############################################################################################################\n",
    "# create inputs\n",
    "# if args.use_acoustic_input:\n",
    "#     inputs = inputs.concat(ssl_reps)\n",
    "\n",
    "###############################################################################################################\n",
    "# forward pass\n",
    "logits = respeller(text[:13])\n",
    "logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b32f95-f595-4966-be96-1dabbde81dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0132145b-00a1-47d7-8268-c76741960b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_embedding_indices = quantiser(logits, produce_targets=True)[\"targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339a2ee-f9c2-4242-b118-6c973855a99b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_embedding_indices.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753cd43-333d-4511-9e10-805b013a5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_embeddings = quantiser(logits, produce_targets=False)[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c56b3-5cf5-4b8c-894e-657892d09c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecfa9bf-4a06-43e1-8078-122f21efb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mel = tts(g_embeddings, use_gt_pitch=False, skip_embeddings=True)\n",
    "\n",
    "###############################################################################################################\n",
    "# calculate losses\n",
    "# respelling_loss = respelling_loss_fn(respelling, e2e_asr_predictions)\n",
    "acoustic_loss = acoustic_loss_fn(log_mel, gt_log_mel)\n",
    "\n",
    "###############################################################################################################\n",
    "# backward pass\n",
    "loss = acoustic_loss\n",
    "loss.backward()\n",
    "\n",
    "###############################################################################################################\n",
    "# log tensorboard metrics\n",
    "\n",
    "###############################################################################################################\n",
    "# validation set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9224dac-da07-4679-9acb-57bcd8205299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
